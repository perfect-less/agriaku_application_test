{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Number 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question:\n",
    "> You were asked to convert your model to API, so that the researchers can perform the alcohol identification in real-time. How would you do this (you donâ€™t have to make the actual API)?\n",
    "\n",
    "I'll assume that we don't need to handle the sensor readings part directly, and the input given to our API will just be the same as how it on the datasets we get. Which means we don't need to actually talked to hardware and process the signal directly. I'll also assume that this API will be impemented in python (perhaps with flask for web server) and not other backend languages like Go or C#."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Http REST API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the kind of API I'll make is just simple REST API where our program will listen to its specified port (e.g. `3306`) where perhaps we could assign route `/predict` to be able to receive POST request that carries the features we need (MIP and NP readings).\n",
    "\n",
    "When POST request received, the programs then will parse the incoming JSONs, obtain MIP and NP readings, doing pre-processing (scaling and calculating MIP/NP), call the model to make prediction, convert back the predictions into JSONs, and finally send back the result as http response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert notebooks to saved the best trained model\n",
    "\n",
    "The current state of notebooks 2 and 3 is not yet ready for creating an API, because first we need to save our models. For scikit model it could be saved into pickle file, in case of tensorflow ANN model can be saved into `.keras` file or even `.tflite` for better performance.\n",
    "\n",
    "After the model were saved then we can begin building an http server for our program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building http server\n",
    "\n",
    "In the past I've tried a simple deployment of a tensorflow model by saving the model into `.tflite` format and later use python server using flask to listen for request. Below is a rought idea of how our program will work.\n",
    "\n",
    " 1. Here we can specified a route (e.g. `/predict`) to listen for POST request, when a request arived a function to handle it run.\n",
    " 2. The function the processed the incoming JSONs, if the format isn't right we could return an error response back\n",
    " 3. If the JSONs is valid, we can do pre-processing, that is scaling the data and calculating additional features (e.g. `MIP/NP ratio`)\n",
    " 4. After hat we then can call our model, it is important to load the model at the start up of our program so that it will be ready and won't add up an overhead when the request is coming.\n",
    " 5. We could do post-process to the prediction results of our model if necessary.\n",
    " 6. Pack our predictions into the body of http response and send the response.\n",
    "\n",
    " Here, the API to our model is the `/predict` route with our specified formatting of the POST request body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deployment\n",
    "Perhaps it will be wise to package everything inside a docker container, or if our program is the only service inside the VM we might as well just put our program there. Our program is very simple, it doesn't need to cache or store anything into disk or even databases. So I think the simple deployment scheme of just puting all necessary code, install all necessary packages, and starting the program will work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
